{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 采集url文本内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import os\n",
    "\n",
    "class crawlText(object):\n",
    "    def __init__(self, base_url):\n",
    "        self.base_url = base_url\n",
    "        self.visited_urls = set()\n",
    "        self.headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.66 Safari/537.36'\n",
    "        }\n",
    "        self.file_path = 'website_texts.txt'\n",
    "\n",
    "    # 获取网页信息\n",
    "    def get_html(self, url):\n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers, timeout=10)\n",
    "            response.raise_for_status()  # 检查请求是否成功\n",
    "            html = response.content.decode('utf-8')\n",
    "            return html\n",
    "        except (requests.RequestException, requests.exceptions.ChunkedEncodingError) as e:\n",
    "            print(f'Error fetching {url}: {e}')\n",
    "            return None\n",
    "\n",
    "    # 提取并保存网页中的所有文本信息\n",
    "    def extract_and_save_text(self, html):\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        texts = soup.stripped_strings\n",
    "        with open(self.file_path, 'a', encoding='utf-8') as file:\n",
    "            for text in texts:\n",
    "                file.write(text)\n",
    "                file.write('\\n')\n",
    "\n",
    "    # 提取网页中的所有链接\n",
    "    def get_all_links(self, html, base_url):\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "        links = set()\n",
    "        for a_tag in soup.find_all('a', href=True):\n",
    "            href = a_tag['href']\n",
    "            full_url = urljoin(base_url, href)\n",
    "            # 确保链接是同一域名下的\n",
    "            if urlparse(full_url).netloc == urlparse(self.base_url).netloc:\n",
    "                links.add(full_url)\n",
    "        return links\n",
    "\n",
    "    # 递归遍历所有链接并提取文本\n",
    "    def crawl(self, url):\n",
    "        if url in self.visited_urls:\n",
    "            return\n",
    "        print(f'Crawling: {url}')\n",
    "        self.visited_urls.add(url)\n",
    "        html = self.get_html(url)\n",
    "        if html:\n",
    "            self.extract_and_save_text(html)\n",
    "            links = self.get_all_links(html, url)\n",
    "            for link in links:\n",
    "                self.crawl(link)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    base_url = 'https://shop.10086.cn/mall_871_871.html'\n",
    "    danmu = crawlText(base_url)\n",
    "    # 清空之前的文件内容\n",
    "    if os.path.exists(danmu.file_path):\n",
    "        os.remove(danmu.file_path)\n",
    "    danmu.crawl(base_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清理数据（只保留长度大于100的缅甸语）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def is_burmese(text):\n",
    "    # 缅甸语的 Unicode 范围是 U+1000 到 U+109F\n",
    "    burmese_pattern = re.compile(r'[\\u1000-\\u109F]')\n",
    "    return bool(burmese_pattern.search(text))\n",
    "\n",
    "def clean_text_from_file(filename):\n",
    "    data = []\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            # 去除HTML标签\n",
    "            line = BeautifulSoup(line, \"lxml\").text\n",
    "            # 去除首尾空白字符\n",
    "            line = line.strip()\n",
    "            # 去除多余的中间空白字符\n",
    "            line = ' '.join(line.split())\n",
    "            # 检查行是否包含缅甸语字符且长度不小于100\n",
    "            if is_burmese(line) and len(line) >= 100:\n",
    "                data.append(line)\n",
    "    \n",
    "    # 将数据转换为 DataFrame 并去重\n",
    "    df = pd.DataFrame(data, columns=['text'])\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 从文件中清理数据\n",
    "filename = 'website_texts.txt'\n",
    "cleaned_df = clean_text_from_file(filename)\n",
    "\n",
    "# 将清理后的数据写入到CSV文件中\n",
    "output_filename = 'cleaned_data.csv'\n",
    "cleaned_df.to_csv(output_filename, index=False, encoding='utf-8')\n",
    "\n",
    "# 输出结果（可选）\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 拆分数据集并保存到EXCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned CSV file\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Calculate the size of each chunk\n",
    "chunk_size = len(df) // 6\n",
    "\n",
    "# Split the DataFrame into 6 chunks and save each chunk to an Excel file\n",
    "for i in range(6):\n",
    "    start = i * chunk_size\n",
    "    if i == 5:\n",
    "        # Make sure the last chunk includes any remaining rows\n",
    "        end = len(df)\n",
    "    else:\n",
    "        end = (i + 1) * chunk_size\n",
    "    \n",
    "    chunk_df = df.iloc[start:end]\n",
    "    chunk_df.to_excel(f\"cleaned_data_part_{i+1}.xlsx\", index=False)\n",
    "\n",
    "print(\"Data has been split into 6 Excel files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成带国家名的运营商短信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from googletrans import Translator\n",
    "import pandas as pd\n",
    "\n",
    "def ggtran(text, dest='en', src='auto'):\n",
    "    \"\"\"\n",
    "    googletrans api 翻译调用\n",
    "    :param text: 要翻译的原文\n",
    "    :param dest: 翻译后输出的语言种类\n",
    "    :param src: 原文的语言种类（auto为默认识别）\n",
    "    :return: 翻译后的内容\n",
    "    \"\"\"\n",
    "    translator = Translator()\n",
    "    try:\n",
    "        result = translator.translate(text, dest=dest, src=src)\n",
    "        return result.text\n",
    "    except Exception as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        return None\n",
    "                \n",
    "def generate_sms_messages():\n",
    "    # 所有国家列表\n",
    "    countries = [\"阿尔巴尼亚\", \"阿富汗\", \"阿根廷\", \"阿联酋\", \"阿曼\", \"阿塞拜疆\", \"埃及\", \"埃塞俄比亚\", \"艾伦岛（奥兰府）\", \"爱奥尼亚\", \"爱尔兰\", \"爱沙尼亚\", \"安的列斯群岛\", \"奥地利\", \"奥克尼群岛\", \"澳大利亚,巴布亚新几内亚\", \"巴基斯坦\", \"巴拉圭\", \"巴勒斯坦\", \"巴林\", \"巴拿马\", \"巴西\", \"白俄罗斯\", \"保加利亚\", \"北爱尔兰,梵蒂冈\", \"菲律宾\", \"斐济\", \"芬兰\", \"刚果\", \"刚果民主共和国\", \"哥伦比亚\", \"哥斯达黎加\", \"哥特兰岛\", \"格鲁吉亚\", \"古巴\", \"瓜德罗普岛\", \"关岛\", \"圭亚那\", \"哈萨克斯坦\", \"海峡群岛\", \"韩国\", \"北马其顿\", \"贝弗敖群岛\", \"贝宁\", \"比利时\", \"波多黎各\", \"波恩荷尔摩岛,波黑\", \"波兰\", \"伯罗奔尼撒\", \"博茨瓦纳\", \"布基纳法索\", \"丹麦\", \"丹麦措辛厄岛\", \"丹麦朗厄兰岛\", \"德国\", \"多米尼加共和国\", \"俄罗斯\", \"厄瓜多尔\", \"厄兰岛\", \"法国\", \"法罗群岛\", \"法属圭亚那,科特迪瓦（象牙海岸）\", \"科威特\", \"科西嘉岛\", \"克里特岛\", \"克罗地亚\", \"库拉索岛和博奈尔岛\", \"拉脱维亚\", \"老挝\", \"立陶宛\", \"利比里亚\", \"列支敦士登\", \"留尼汪岛\", \"卢森堡\", \"卢旺达\", \"罗德岛,郝布里底群岛\", \"荷兰\", \"黑山\", \"洪都拉斯\", \"基克拉泽\", \"基里巴斯\", \"吉布提\", \"吉尔吉斯斯坦\", \"几内亚\", \"几内亚比绍\", \"加拿大\", \"加纳\", \"加蓬\", \"柬埔寨\", \"捷克\", \"喀麦隆\", \"卡塔尔,罗弗敦群岛\", \"罗马尼亚\", \"马德拉群岛\", \"马尔代夫\", \"马耳他\", \"马拉维\", \"马来西亚\", \"马里\", \"马提尼岛\", \"马约特岛\", \"曼岛\", \"毛里求斯\", \"美国（本土）\", \"美属维尔京群岛\", \"蒙古\", \"孟加拉国\", \"秘鲁,缅甸\", \"摩尔多瓦\", \"摩洛哥\", \"摩纳哥\", \"墨西哥\", \"纳米比亚\", \"南贝佛兰岛\", \"南非\", \"南苏丹\", \"瑙鲁\", \"尼泊尔\", \"尼加拉瓜\", \"尼日尔\", \"尼日利亚\", \"挪威\", \"葡萄牙\", \"日本\", \"瑞典\", \"瑞士,萨尔瓦多\", \"萨摩亚\", \"塞班岛\", \"塞尔维亚\", \"塞内加尔\", \"塞浦路斯\", \"塞舌尔\", \"沙特\", \"设得兰群岛\", \"圣港岛\", \"圣马力诺\", \"斯里兰卡\", \"斯洛伐克\", \"斯洛文尼亚\", \"斯图尔特岛\", \"斯威士兰,斯雅尔巴群岛\", \"苏丹\", \"苏里南\", \"所罗门群岛\", \"塔吉克斯坦\", \"泰国\", \"坦桑尼亚\", \"汤加\", \"特立尼达和多巴哥\", \"天宁岛\", \"土耳其\", \"瓦努阿图\", \"危地马拉\", \"文莱\", \"乌干达\", \"乌克兰\", \"乌拉圭,乌兹别克斯坦\", \"西奥仑群岛\", \"西班牙\", \"西班牙福门特拉\", \"西班牙加那利群岛\", \"西班牙卡夫雷拉岛\", \"西班牙卡那利群岛\", \"西班牙马略卡岛\", \"西班牙梅诺卡岛\", \"西班牙美利利亚,西班牙切乌塔\", \"西班牙伊比沙岛\", \"西佛里西亚群岛\", \"希腊\", \"夏威夷\", \"新加坡\", \"新西兰\", \"匈牙利\", \"亚美尼亚\", \"亚述尔群岛\", \"伊拉克\", \"伊朗\", \"以色列\", \"意大利\", \"意大利撒丁岛,意大利西西里岛\", \"印度\", \"印度尼西亚\", \"英国\", \"约旦河西岸\", \"越南\", \"赞比亚\", \"泽西岛\", \"乍得\", \"智利\", \"中非共和国\", \"中国澳门\", \"中国台湾\", \"中国香港\", \"海地\", \"也门\", \"冰岛\", \"科摩罗\", \"圣马丁（法属）\", \"圣巴泰勒米\", \"北马里亚纳群岛\", \"罗塔岛\"]    \n",
    "    \n",
    "    def get_random_dates():\n",
    "        start_date = datetime(2024, 1, 1)\n",
    "        random_days = random.randint(0, 364)\n",
    "        random_hours = random.randint(0, 23)\n",
    "        random_minutes = random.randint(0, 59)\n",
    "        \n",
    "        order_time = start_date + timedelta(days=random_days, hours=random_hours, minutes=random_minutes)\n",
    "        end_time = order_time + timedelta(days=90)\n",
    "        \n",
    "        return (\n",
    "            order_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            end_time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            order_time.strftime(\"%Y-%m-%d\")\n",
    "        )\n",
    "\n",
    "    def get_random_price():\n",
    "        return random.randrange(158, 359, 10)\n",
    "\n",
    "    def get_random_country_group():\n",
    "        # 随机选择12-15个国家\n",
    "        group_size = random.randint(12, 15)\n",
    "        return random.sample(countries, group_size)\n",
    "\n",
    "    sms_template = \"\"\"【订购提醒】尊敬的客户，您好！您已于{order_date}通过中国移动线上渠道成功办理15G国漫流量月包_基础包。具体业务内容如下：\n",
    "1、资费内容：{price}元/次，{countries}\n",
    "2、生效时间：{start_time}\n",
    "3、失效时间：{end_time}\n",
    "若需提前解约您可前往号码归属地沟通100服务厅或拨打10086咨询办理。感谢您的参与！【中国移动】\"\"\"\n",
    "\n",
    "    sms_template_my = \"\"\"[အော်ဒါသတိပေးချက်] ချစ်လှစွာသော customer၊ မင်္ဂလာပါ။ သင်သည် China Mobile ၏အွန်လိုင်းချန်နယ်များမှ {order_date} တွင် 15G National Comic Traffic Monthly Package_Basic Package အတွက် အောင်မြင်စွာ လျှောက်ထားပြီးဖြစ်သည်။ အထူးစီးပွားရေးလုပ်ငန်းအကြောင်းအရာမှာ အောက်ပါအတိုင်းဖြစ်သည်။\n",
    "1. စည်းကြပ်ခွန်ပါဝင်မှု-အကြိမ် {price} ယွမ်，{countries}\n",
    "2. အကျိုးသက်ရောက်ချိန်- {start_time}\n",
    "3. သက်တမ်းကုန်ချိန်- {end_time}\n",
    "စာချုပ်ကို ကြိုတင်ဖျက်သိမ်းလိုပါက နံပါတ်ပိုင်ဆိုင်သည့်နေရာကို သွားပြီး 100 ဝန်ဆောင်မှုခန်းမသို့ ဆက်သွယ်မေးမြန်းနိုင်သည် သို့မဟုတ် 10086 သို့ခေါ်ဆို၍ ညှိနှိုင်းဆွေးနွေးနိုင်ပါသည်။ သင်၏ပါဝင်မှုအတွက် ကျေးဇူးတင်ပါသည်။ [တရုတ်မိုဘိုင်း]\"\"\"\n",
    "\n",
    "    # 生成数据\n",
    "    data = []\n",
    "    for i in range(150):\n",
    "        start_time, end_time, order_date = get_random_dates()\n",
    "        price = get_random_price()\n",
    "        country_group = get_random_country_group()\n",
    "        countries_str = \", \".join(country_group)\n",
    "        \n",
    "        message_cn = sms_template.format(\n",
    "            countries=countries_str,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            order_date=order_date,\n",
    "            price=price\n",
    "        )\n",
    "        \n",
    "        message_my = sms_template_my.format(\n",
    "            countries=ggtran(countries_str, dest='en'),\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "            order_date=order_date,\n",
    "            price=price\n",
    "        )\n",
    "        \n",
    "        data.append({\n",
    "            '序号': i + 1,\n",
    "            '订购日期': order_date,\n",
    "            '生效时间': start_time,\n",
    "            '失效时间': end_time,\n",
    "            '资费(元/次)': price,\n",
    "            '包含国家': countries_str,\n",
    "            '短信内容(中文)': message_cn,\n",
    "            '短信内容(缅甸语)': message_my\n",
    "        })\n",
    "    \n",
    "    # 创建DataFrame并保存到Excel\n",
    "    df = pd.DataFrame(data)\n",
    "    excel_path = 'sms_messages1.xlsx'\n",
    "    df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "    print(f\"数据已保存到 {excel_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# 生成数据并保存到Excel\n",
    "messages_df = generate_sms_messages()\n",
    "messages_df.head()  # 显示前5行数据预览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ai4privacy/pii-masking-200k\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "2.7.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
